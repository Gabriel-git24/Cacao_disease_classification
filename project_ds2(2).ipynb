{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gabriel-git24/Cacao_disease_classification/blob/main/project_ds2(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Q5Y9BxKIFs0",
        "outputId": "37b9fee7-e671-4c3a-b52c-3668d0279a35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner --quiet\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import keras_tuner as kt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ykxa3buBFm8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "collapsed": true,
        "outputId": "86233ff5-dacf-4bfb-d4b1-8c1e5cbd2af2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!pip install split-folders --quiet\\n\\nimport splitfolders\\n\\ninput_folder = \"/content/drive/MyDrive/Data_Science_Project_fall2024/Data Science Project/Enfermedades Cacao/binary_classification\"\\noutput_folder = \"/content/drive/MyDrive/Data_Science_Project_fall2024/Data Science Project/Enfermedades Cacao/binary_classification/Cacao_Splits\"\\n\\nsplitfolders.ratio(\\n    input_folder,\\n    output=output_folder,\\n    seed=42,\\n    ratio = (0.7, 0.15, 0.15),\\n    group_prefix=None,\\n    move=False\\n)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# need to sort images into folders based on their labels\n",
        "# # DO NOT UNCOMMENT THIS,\n",
        "# THIS IS TO DIVIDE THE IMAGES INTO FOLDERS BASED ON THEIR LABELS\n",
        "# AND THEN USES SPLITFOLDER TO CREATE TRAIN TEST VALIDATION\n",
        "'''\n",
        "sana = \"/content/drive/MyDrive/Data_Science_Project_fall2024/Data Science Project/Enfermedades Cacao/Sana\"\n",
        "fito = \"/content/drive/MyDrive/Data_Science_Project_fall2024/Data Science Project/Enfermedades Cacao/Fito\"\n",
        "monilia = \"/content/drive/MyDrive/Data_Science_Project_fall2024/Data Science Project/Enfermedades Cacao/Monilia\"\n",
        "\n",
        "def filter_images(directory):\n",
        "  image_extension = [\".jpg\", \".jpeg\", \".png\"]\n",
        "  destination_dir = directory + \"_images\" # defining image destination path\n",
        "\n",
        "  os.makedirs(destination_dir, exist_ok=True) # creating the destination\n",
        "\n",
        "  for filename in os.listdir(directory):\n",
        "    file_path = os.path.join(directory, filename)\n",
        "    if os.path.isfile(file_path) and filename.lower().endswith(tuple(image_extension)):\n",
        "      shutil.copy2(file_path, destination_dir)\n",
        "\n",
        "filter_images(sana)\n",
        "filter_images(fito)\n",
        "filter_images(monilia)'''\n",
        "\n",
        "'''!pip install split-folders --quiet\n",
        "\n",
        "import splitfolders\n",
        "\n",
        "input_folder = \"/content/drive/MyDrive/Data_Science_Project_fall2024/Data Science Project/Enfermedades Cacao/binary_classification\"\n",
        "output_folder = \"/content/drive/MyDrive/Data_Science_Project_fall2024/Data Science Project/Enfermedades Cacao/binary_classification/Cacao_Splits\"\n",
        "\n",
        "splitfolders.ratio(\n",
        "    input_folder,\n",
        "    output=output_folder,\n",
        "    seed=42,\n",
        "    ratio = (0.7, 0.15, 0.15),\n",
        "    group_prefix=None,\n",
        "    move=False\n",
        ")'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "split_dir = \"/content/drive/MyDrive/Data_Science_Project_fall2024/Data Science Project/Enfermedades Cacao/binary_classification/Cacao_Splits\"\n",
        "checkpoint_path = \"/content/drive/MyDrive/2/best_model.keras\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    zoom_range=0.15,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=f\"{split_dir}/train\",\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"binary\"\n",
        ")\n",
        "\n",
        "validation_generator = val_test_datagen.flow_from_directory(\n",
        "    directory=f\"{split_dir}/val\",\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"binary\"\n",
        ")\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_directory(\n",
        "    directory=f\"{split_dir}/test\",\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"binary\"\n",
        ")"
      ],
      "metadata": {
        "id": "Kj3Ej_Ui97L8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61a7eee8-f651-4b64-cf76-edfeea43eb28"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 218 images belonging to 2 classes.\n",
            "Found 46 images belonging to 2 classes.\n",
            "Found 48 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#HYPERPARAMETER TUNING USING KERAS TUNER\n",
        "\n",
        "def build_model(hp):\n",
        "  base_model = MobileNetV2(\n",
        "      weights = \"imagenet\",\n",
        "      include_top = False,\n",
        "      input_shape = image_size + (3,) # the 3 is for the color channel, in this case the three primary colors\n",
        "  )\n",
        "  base_model.trainable = False\n",
        "\n",
        "  x = base_model.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "  #tuning the number of units in the dense layer\n",
        "  hp_units = hp.Int(\"units\", min_value=32, max_value=256, step=32)\n",
        "  x = Dense(units=hp_units, activation=\"relu\")(x)\n",
        "\n",
        "  #tuning the dropout rate\n",
        "  hp_dropout = hp.Float(\"dropout\", min_value=0.2, max_value=0.5, step=0.1)\n",
        "  x = Dropout(hp_dropout)(x)\n",
        "\n",
        "  predictions = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "  model = Model(\n",
        "      inputs = base_model.input,\n",
        "      outputs = predictions\n",
        "  )\n",
        "\n",
        "  #tuning the learning rate\n",
        "  hp_learning_rate = hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  # compiling the model\n",
        "  model.compile(\n",
        "      optimizer = Adam(learning_rate=hp_learning_rate),\n",
        "      loss = \"binary_crossentropy\",\n",
        "      metrics = [\"accuracy\"]\n",
        "  )\n",
        "\n",
        "  return model\n",
        "\n",
        "# tuner = kt.Hyperband(\n",
        "#     build_model,\n",
        "#     objective=\"val_accuracy\",\n",
        "#     max_epochs=10,\n",
        "#     factor=3,\n",
        "#     directory=\"my_dir\",\n",
        "#     project_name=\"my_project\"\n",
        "# )\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor = \"val_loss\",\n",
        "    patience = 5,\n",
        "    restore_best_weights = True\n",
        ")\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=10,\n",
        "    executions_per_trial=2,\n",
        "    directory=\"/content/drive/MyDrive/2\",\n",
        "    project_name=\"mobile_net_tuning\"\n",
        ")\n",
        "\n",
        "tuner.search(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTXXHdDYP99-",
        "outputId": "4fade8f3-7c5d-471d-bb41-1bbd08ab008c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 18m 54s]\n",
            "val_accuracy: 0.782608687877655\n",
            "\n",
            "Best val_accuracy So Far: 0.804347813129425\n",
            "Total elapsed time: 14h 40m 39s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The optimal hyperparameters are:\n",
        "- Units in Dense layer: {best_hps.get('units')}\n",
        "- Dropout rate: {best_hps.get('dropout'):.2f}\n",
        "- Learning rate for Adam: {best_hps.get('learning_rate'):.5f}\n",
        "\"\"\")\n",
        "\n",
        "# Getting the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "id": "V_TCWVwUVMYd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a415fb0-a274-4516-948c-6e7feadf6ed3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The optimal hyperparameters are:\n",
            "- Units in Dense layer: 160\n",
            "- Dropout rate: 0.20\n",
            "- Learning rate for Adam: 0.00100\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a checkpointing to beat timeout on colab\n",
        "\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath = checkpoint_path,\n",
        "    save_weights_only = False,\n",
        "    monitor = \"val_loss\",\n",
        "    save_best_only = True,\n",
        "    verbose = 1\n",
        ")\n",
        "\n",
        "#final_model on training set\n",
        "history = best_model.fit(\n",
        "    train_generator,\n",
        "    epochs=50,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[early_stopping, model_checkpoint_callback]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1K8gToD7zki",
        "outputId": "e15a65b6-b644-4e29-8882-957ffa9d8dbd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7546 - loss: 0.4515\n",
            "Epoch 1: val_loss improved from inf to 0.55887, saving model to /content/drive/MyDrive/2/best_model.keras\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 10s/step - accuracy: 0.7578 - loss: 0.4496 - val_accuracy: 0.7609 - val_loss: 0.5589\n",
            "Epoch 2/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.7876 - loss: 0.4539\n",
            "Epoch 2: val_loss improved from 0.55887 to 0.46409, saving model to /content/drive/MyDrive/2/best_model.keras\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 8s/step - accuracy: 0.7883 - loss: 0.4513 - val_accuracy: 0.8043 - val_loss: 0.4641\n",
            "Epoch 3/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7249 - loss: 0.5551\n",
            "Epoch 3: val_loss did not improve from 0.46409\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 8s/step - accuracy: 0.7289 - loss: 0.5470 - val_accuracy: 0.7609 - val_loss: 0.4834\n",
            "Epoch 4/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8405 - loss: 0.3971\n",
            "Epoch 4: val_loss did not improve from 0.46409\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 8s/step - accuracy: 0.8380 - loss: 0.3949 - val_accuracy: 0.7826 - val_loss: 0.5820\n",
            "Epoch 5/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8306 - loss: 0.3352\n",
            "Epoch 5: val_loss improved from 0.46409 to 0.45506, saving model to /content/drive/MyDrive/2/best_model.keras\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 9s/step - accuracy: 0.8323 - loss: 0.3335 - val_accuracy: 0.8043 - val_loss: 0.4551\n",
            "Epoch 6/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7798 - loss: 0.4456\n",
            "Epoch 6: val_loss did not improve from 0.45506\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8s/step - accuracy: 0.7867 - loss: 0.4375 - val_accuracy: 0.7609 - val_loss: 0.5868\n",
            "Epoch 7/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8685 - loss: 0.3425\n",
            "Epoch 7: val_loss improved from 0.45506 to 0.43005, saving model to /content/drive/MyDrive/2/best_model.keras\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 8s/step - accuracy: 0.8695 - loss: 0.3404 - val_accuracy: 0.8261 - val_loss: 0.4300\n",
            "Epoch 8/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8296 - loss: 0.3555\n",
            "Epoch 8: val_loss did not improve from 0.43005\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8s/step - accuracy: 0.8314 - loss: 0.3507 - val_accuracy: 0.7826 - val_loss: 0.4600\n",
            "Epoch 9/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8666 - loss: 0.2954\n",
            "Epoch 9: val_loss did not improve from 0.43005\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 9s/step - accuracy: 0.8666 - loss: 0.2984 - val_accuracy: 0.7826 - val_loss: 0.4732\n",
            "Epoch 10/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9009 - loss: 0.2543\n",
            "Epoch 10: val_loss did not improve from 0.43005\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.8984 - loss: 0.2576 - val_accuracy: 0.8043 - val_loss: 0.5279\n",
            "Epoch 11/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8711 - loss: 0.3008\n",
            "Epoch 11: val_loss did not improve from 0.43005\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.8672 - loss: 0.3027 - val_accuracy: 0.7174 - val_loss: 0.6350\n",
            "Epoch 12/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8421 - loss: 0.3428\n",
            "Epoch 12: val_loss did not improve from 0.43005\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8s/step - accuracy: 0.8423 - loss: 0.3431 - val_accuracy: 0.8261 - val_loss: 0.4338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "best_model = tf.keras.models.load_model(checkpoint_path)\n",
        "test_loss, test_accuracy = best_model.evaluate(test_generator)\n",
        "\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "id": "EYdqgJgSLn_X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7798cbe3-e896-4968-b552-bb8f957b6314"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.6806 - loss: 0.6167\n",
            "Test Loss: 0.5632346868515015\n",
            "Test Accuracy: 0.7083333134651184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EJ-OR-5s3103",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "ddaf1aba-d546-4831-945f-16448bc95dcc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# will be using transferred learning because of limitted data, computational efficient, and more accurate\\n\\n# loading a pretrained base model\\n\\nbase_model = MobileNetV2(\\n    weights=\"imagenet\",\\n    include_top = False,\\n    input_shape = image_size + (3,),\\n)\\n\\nbase_model.trainable = False\\n\\nx = base_model.output\\n\\n# Adding three layers to MobileNetV2\\nx = GlobalAveragePooling2D()(x)\\nx = Dense(64, activation=\\'relu\\')(x)\\nx = Dropout(0.5)(x)\\npredictions = Dense(1, activation=\"sigmoid\")(x)\\n\\nmodel = Model(\\n    inputs = base_model.input,\\n    outputs = predictions\\n)\\n\\nmodel.compile(\\n    optimizer = Adam(learning_rate=0.0001),\\n    loss=\"binary_crossentropy\",\\n    metrics=[\"accuracy\"]\\n)\\n\\n#stop training if validation loss doesn\\'t improve for 5 consecutive epochs\\nearly_stopping = EarlyStopping(\\n    monitor=\"val_loss\",\\n    patience=5,\\n    restore_best_weights=True\\n)\\n\\n#use this to enable checkpointing (save your progress)\\nmodel_checkpoint_callback = ModelCheckpoint(\\n    filepath=checkpoint_path,\\n    save_weights_only=False,\\n    monitor=\"val_loss\",\\n    mode=\"min\",\\n    save_best_only=True,\\n    verbose=1\\n)\\n\\n#Training the model\\nhistory = model.fit(\\n    train_generator,\\n    epochs=50,\\n    validation_data = validation_generator,\\n    callbacks=[early_stopping, model_checkpoint_callback]\\n)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "'''# will be using transferred learning because of limitted data, computational efficient, and more accurate\n",
        "\n",
        "# loading a pretrained base model\n",
        "\n",
        "base_model = MobileNetV2(\n",
        "    weights=\"imagenet\",\n",
        "    include_top = False,\n",
        "    input_shape = image_size + (3,),\n",
        ")\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "\n",
        "# Adding three layers to MobileNetV2\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = Model(\n",
        "    inputs = base_model.input,\n",
        "    outputs = predictions\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer = Adam(learning_rate=0.0001),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "#stop training if validation loss doesn't improve for 5 consecutive epochs\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "#use this to enable checkpointing (save your progress)\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=False,\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\",\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "#Training the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=50,\n",
        "    validation_data = validation_generator,\n",
        "    callbacks=[early_stopping, model_checkpoint_callback]\n",
        ")'''"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHv7WRf80qNc7bPUM6YuBg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}